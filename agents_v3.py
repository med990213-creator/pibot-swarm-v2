"""
Pi Swarm Agents Core v3.0 - LLM-DRIVEN INTELLIGENCE
Inspired by Cline: Using local LLMs as the reasoning engine for code fixes.
"""

import os
import re
import json
import urllib.request

class LLMBrain:
    """ÿßŸÑÿ±ÿßÿ®ÿ∑ ŸÖÿπ ÿπŸÇŸÑ ÿßŸÑÿ≥ÿ±ÿ® (Ollama / Qwen)"""
    def __init__(self, model="qwen2.5:1.5b"):
        self.model = model
        self.url = "http://localhost:11434/api/generate"

    def reason(self, prompt: str):
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False
        }
        try:
            req = urllib.request.Request(self.url, data=json.dumps(payload).encode(), method="POST")
            with urllib.request.urlopen(req) as res:
                return json.loads(res.read().decode())['response']
        except Exception as e:
            return f"Error connecting to brain: {e}"

class AnalysisAgent:
    def __init__(self):
        self.brain = LLMBrain()

    def analyze_and_patch(self, file_path: str):
        print(f"üõ°Ô∏è [Analyst] Auditing via LLM-Reasoning: {file_path}")
        with open(file_path, 'r') as f:
            code = f.read()

        # ÿµŸäÿßÿ∫ÿ© ÿßŸÑÿ∑ŸÑÿ® ŸÑŸÑÿπŸÇŸÑ (Cline Style)
        prompt = f"""
        System: You are an elite Solana Security Engineer. 
        Task: Analyze the following Rust code and FIX any vulnerabilities (especially UncheckedAccount).
        Return ONLY the fixed code block, no explanations.

        CODE:
        {code}
        """
        
        print("üß† [Brain] Thinking about the fix...")
        fixed_code = self.brain.reason(prompt)
        
        if "Error" not in fixed_code:
            print(f"‚úÖ [Analyst] Fix generated by Sovereign Intelligence.")
            return fixed_code
        return None

if __name__ == "__main__":
    # ÿ™ÿ¨ÿ±ÿ®ÿ© ÿ™ÿ¥ÿ∫ŸäŸÑ "ÿßŸÑÿπŸÇŸÑ"
    agent = AnalysisAgent()
    print(agent.analyze_and_patch("lab_vuln.rs"))
